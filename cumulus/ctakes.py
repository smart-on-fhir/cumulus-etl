"""Interface for talking to a cTAKES server"""

import base64
import cgi
import hashlib
import logging
import os
from typing import List

import ctakesclient
from fhirclient.models.documentreference import DocumentReference

from cumulus import common, fhir_common, store


def covid_symptoms_extract(cache: store.Root, docref: DocumentReference) -> List[dict]:
    """
    Extract a list of Observations from NLP-detected symptoms in physician notes

    :param cache: Where to cache NLP results
    :param docref: Physician Note
    :return: list of NLP results encoded as FHIR observations
    """
    docref_id = docref.id
    _, subject_id = fhir_common.unref_resource(docref.subject)

    if not docref.context or not docref.context.encounter:
        logging.warning('No valid encounters for symptoms')  # ideally would print identifier, but it's PHI...
        return []
    _, encounter_id = fhir_common.unref_resource(docref.context.encounter[0])

    # Find the physician note among the attachments
    for content in docref.content:
        if content.attachment.contentType and content.attachment.data:
            mimetype, params = cgi.parse_header(content.attachment.contentType)
            if mimetype == 'text/plain':  # just grab first text we find
                charset = params.get('charset', 'utf8')
                physician_note = base64.standard_b64decode(content.attachment.data).decode(charset)
                break
    else:
        logging.warning('No text/plain content for symptoms')  # ideally would print identifier, but it's PHI...
        return []

    # Strip this "line feed" character that often shows up in notes and is confusing for cNLP.
    physician_note = physician_note.replace('Â¿', ' ')

    # FIXME: Ideally this prefix would be study-specific like 'covid_symptoms', but we use `version1` for
    #  historical reasons. Ideally we'd also be able to ask ctakesclient for NLP algorithm information as part of
    #  this prefix. For now, we'll manually update this prefix if/when the cTAKES algorithm we use changes.
    prefix = 'version1'

    try:
        ctakes_json = extract(cache, prefix, physician_note)
    except Exception as exc:  # pylint: disable=broad-except
        logging.error('Could not extract symptoms: %s', exc)
        return []

    matches = ctakes_json.list_sign_symptom(ctakesclient.typesystem.Polarity.pos)

    # OK we have cTAKES symptoms. But let's also filter through cNLP transformers to remove any that are negated
    # there too. We have found this to yield better results than cTAKES alone.
    try:
        spans = ctakes_json.list_spans(matches)
        polarities_cnlp = list_polarity(cache, prefix, physician_note, spans)
    except Exception:  # pylint: disable=broad-except
        logging.exception('Could not check negation')
        polarities_cnlp = [ctakesclient.typesystem.Polarity.pos] * len(matches)  # fake all positives

    # Now filter out any non-positive matches
    positive_matches = []
    for i, match in enumerate(matches):
        if polarities_cnlp[i] == ctakesclient.typesystem.Polarity.pos:
            positive_matches.append({
                'id': f'{docref_id}.{i}',
                'docref_id': docref.id,
                'encounter_id': encounter_id,
                'subject_id': subject_id,
                'match': match.as_json(),
            })

    return positive_matches


def extract(cache: store.Root, prefix: str, sentence: str) -> ctakesclient.typesystem.CtakesJSON:
    """
    This is a version of ctakesclient.client.extract() that also uses a cache

    This cache is stored as a series of files in the PHI root. If found, the cached results are used.
    If not found, the cTAKES server is asked to parse the sentence, which can take a while (~20s)
    """
    full_path = cache.joinpath(_target_filename(prefix, sentence))

    try:
        cached_response = common.read_json(full_path)
        result = ctakesclient.typesystem.CtakesJSON(source=cached_response)
    except Exception:  # pylint: disable=broad-except
        result = ctakesclient.client.extract(sentence)
        cache.makedirs(os.path.dirname(full_path))
        common.write_json(full_path, result.as_json())

    return result


def list_polarity(
        cache: store.Root,
        prefix: str,
        sentence: str,
        spans: List[tuple],
) -> List[ctakesclient.typesystem.Polarity]:
    """
    This is a version of ctakesclient.transformer.list_polarity() that also uses a cache

    This cache is stored as a series of files in the PHI root. If found, the cached results are used.
    If not found, the cTAKES server is asked to parse the sentence, which can take a while (~3s)
    """
    if not spans:
        return []

    full_path = cache.joinpath(_target_filename(f'{prefix}-cnlp', sentence))

    try:
        result = [ctakesclient.typesystem.Polarity(x) for x in common.read_json(full_path)]
    except Exception:  # pylint: disable=broad-except
        result = ctakesclient.transformer.list_polarity(sentence, spans)
        cache.makedirs(os.path.dirname(full_path))
        common.write_json(full_path, [x.value for x in result])

    return result


def _target_filename(prefix: str, sentence: str) -> str:
    """Gives the expected cached-result filename for the given sentence"""

    # There are a few parts to the filename:
    # prefix: a study / NLP algorithm version number (unique per study and per NLP algorithm change)
    # partialsum: first 4 characters of the checksum (to help reduce folder sizes where that matters)
    # hashalgo: which hashing algorithm was used
    # checksum: a checksum hash of the whole sentence
    #
    # Resulting in filenames of the form:
    # ctakes-cache/{prefix}/{partialsum}/{hashalgo}-{checksum}.json

    # MD5 and SHA1 have both been broken. Which might not be super important, since we are putting these files
    # in a PHI-capable folder. But still, why make it easier to brute-force.
    # SHA256 is not yet cryptographically broken and is not much slower. Let's just use it.
    # (Actually, on my machine it is faster. Run 'openssl speed md5 sha1 sha256' to see what you get.)
    checksum = hashlib.sha256(sentence.encode('utf8')).hexdigest()
    partial = checksum[0:4]

    return f'ctakes-cache/{prefix}/{partial}/sha256-{checksum}.json'
