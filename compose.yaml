services:

  cumulus-etl-base:
    image: smartonfhir/cumulus-etl:latest
    build:
      context: .
      target: cumulus-etl
    environment:
      - AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY
      - AWS_SESSION_TOKEN
      - AWS_PROFILE
      - AWS_DEFAULT_PROFILE
      - CUMULUS_HUGGING_FACE_URL=http://llama2:8086/
      - URL_CTAKES_REST=http://ctakes-covid:8080/ctakes-web-rest/service/analyze
      - URL_CNLP_NEGATION=http://cnlpt-negation:8000/negation/process
      - URL_CNLP_TERM_EXISTS=http://cnlpt-term-exists:8000/termexists/process
    volumes:
      - $HOME/.aws/:/root/.aws/:ro
      - ctakes-overrides:/ctakes-overrides
    networks:
      - cumulus-etl
    profiles:
      - base

  cumulus-etl:
    extends: cumulus-etl-base
    profiles:
      - etl

  cumulus-etl-gpu:
    extends: cumulus-etl-base
    environment:
      - URL_CNLP_NEGATION=http://cnlpt-negation-gpu:8000/negation/process
      - URL_CNLP_TERM_EXISTS=http://cnlpt-term-exists-gpu:8000/termexists/process
    profiles:
      - etl-gpu

  ctakes-covid-base:
    image: smartonfhir/ctakes-covid:1.1.0
    environment:
      - ctakes_umlsuser=umls_api_key 
      - ctakes_umlspw=$UMLS_API_KEY
    networks:
      - cumulus-etl
    profiles:
      - base
    volumes:
      - ctakes-overrides:/overrides

  ctakes-covid:
    extends: ctakes-covid-base
    profiles:
      - chart-review
      - chart-review-gpu
      - covid-symptom
      - covid-symptom-gpu

  cnlpt-negation:
    image: smartonfhir/cnlp-transformers:negation-0.6.1-cpu
    profiles:
      - chart-review
      - covid-symptom
    networks:
      - cumulus-etl

  cnlpt-negation-gpu:
    image: smartonfhir/cnlp-transformers:negation-0.6.1-gpu
    profiles:
      - chart-review-gpu
      - covid-symptom-gpu
    networks:
      - cumulus-etl
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

  cnlpt-term-exists:
    image: smartonfhir/cnlp-transformers:termexists-0.6.1-cpu
    profiles:
      - covid-symptom
    networks:
      - cumulus-etl

  cnlpt-term-exists-gpu:
    image: smartonfhir/cnlp-transformers:termexists-0.6.1-gpu
    profiles:
      - covid-symptom-gpu
    networks:
      - cumulus-etl
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

  # This is a WIP llama2 setup, currently suitable for running in a g5.xlarge AWS instance.
  llama2:
    image: ghcr.io/huggingface/text-generation-inference:1.0.1
    environment:
      # If you update anything here that could affect NLP results, consider updating the
      # task_version of any tasks that use this docker.
      - HUGGING_FACE_HUB_TOKEN
      - MODEL_ID=meta-llama/Llama-2-13b-chat-hf
      - QUANTIZE=bitsandbytes-nf4  # 4bit
      - PORT=8086
      - REVISION=0ba94ac9b9e1d5a0037780667e8b219adde1908c
    healthcheck:
      # There's no curl or wget inside this container, but there is python3!
      test: ["CMD", "python3", "-c", "import socket; socket.create_connection(('localhost', 8086))"]
      start_period: 20m  # give plenty of time for startup, since we may be downloading a model
    volumes:
      - hf-data:/data
    profiles:
      - hf-test
    networks:
      - cumulus-etl
    ports:
      - 8086:8086
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

  # these images are intended specifically for development work
  cumulus-etl-test:
    extends:
      service: cumulus-etl-base
    build: 
      context: .
      target: cumulus-etl-test
    environment:
      - URL_CTAKES_REST=http://ctakes-covid-test:8080/ctakes-web-rest/service/analyze
      - URL_CNLP_NEGATION=http://cnlp-transformers-test:8000/negation/process
    volumes: 
      - ./:/cumulus-etl/
    working_dir: /cumulus-etl
    command:
      - /cumulus-etl/tests/data/simple/ndjson-input 
      - /cumulus-etl/example-output 
      - /cumulus-etl/example-phi-build 
      - --output-format=ndjson
    profiles:
      - test

  cumulus-etl-test-gpu:
    extends:
      service: cumulus-etl-base
    build: 
      context: .
      target: cumulus-etl-test
    environment:
      - URL_CTAKES_REST=http://ctakes-covid-test:8080/ctakes-web-rest/service/analyze
      - URL_CNLP_NEGATION=http://cnlp-transformers-test-gpu:8000/negation/process
    volumes: 
      - ./:/cumulus-etl/
    working_dir: /cumulus-etl
    command: 
      - /cumulus-etl/tests/data/simple/ndjson-input 
      - /cumulus-etl/example-output 
      - /cumulus-etl/example-phi-build 
      - --output-format=ndjson
    profiles:
      - test-gpu


  ctakes-covid-test:
    extends:
      service: ctakes-covid-base
    profiles:
      - test
      - test-gpu
    ports:
      - 8080:8080

  cnlp-transformers-test:
    image: smartonfhir/cnlp-transformers:negation-latest-cpu
    #build: 
    #  context: ../cnlp_transformers/docker
    #  dockerfile: Dockerfile.cpu
    ports:
      - 8000:8000
    profiles:
      - test
    networks:
      - cumulus-etl

  cnlp-transformers-test-gpu:
    image: smartonfhir/cnlp-transformers:negation-latest-gpu
    #build: 
    #  context: ../cnlp_transformers/docker
    #  dockerfile: Dockerfile.gpu
    ports:
      - 8000:8000
    profiles:
      - test-gpu
    networks:
      - cumulus-etl
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

networks:
  cumulus-etl:
    name: cumulus-etl

volumes:
  ctakes-overrides:
  hf-data:
